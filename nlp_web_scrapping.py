# -*- coding: utf-8 -*-
"""NLP web scrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/160cmsVAbRFOe-joD7cWYvTMKosQisJV1
"""

import nltk

from nltk.corpus import stopwords
dir(stopwords)

ntlk.download('stopwords')

import requests

#accessing website fromurl
webdata=requests.get("https://php.net")

webdata #response code of http protocol

htmldata=webdata.text

htmldata

#importing bs4
from bs4 import BeautifulSoup

soup=BeautifulSoup(htmldata,'html5lib')

type(soup)

clean_data = soup.get_text()

# cleaning
with open('mywebdata.txt','w+') as f:
  f.write(clean_data)

f=open('mywebdata.txt','r')
mydata=f.read()
f.close()

type(mydata)

#split
import time 
for i in mydata.split():
  print(i)
  time.sleep(1)

newdata=[i for i  in mydata.split()]

#NLTK graphs
import matplotlib.pyplot as plt
import nltk

[i for i in dir(nltk)if 'Freq' in  i]#this will plot data for

nlpdata=nltk.FreqDist(newdata1)

nlpdata.plot()

# we can remove stop words from newdata1 then plot the graph
from nltk.corpus import stopwords

# removing stopwords
removedata = [i for i newdata1 if i not in stopwords.words('english')]

# apply NLTK FreqDist
nlpremove=nltk.FreqDist(removedata)

nlpremove.plot(20)

msg='''Ankur kutta kamina hai ek girlfriend bhi nahi ptvai saale ne 50 60 gf bna chuka hai bhai kadar hi nahi hai.'''

# import tokenize
from nltk.tokenize import sent_tokenize
from nltk.tokenize import word_tokenize

#sentence tokenize
sent=sent_tokenize(msg)

sent

# no of sentence
len(sent)

from nltk import stem
from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer

port=PorterStemmer()

port.stem('go')

for i in ['ankur','akshat','ankush']:
  print(port.stem(i))
  time.sleep(1)

